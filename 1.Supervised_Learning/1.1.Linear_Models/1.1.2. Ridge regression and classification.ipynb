{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2. Ridge Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regularization은 계수의 크기에 패널티를 부과하여 최소제곱법의 과적합 문제를 해결하는 정규화 방법입니다.<br><br>\n",
    "또한 L2 Regularization이라고도 부릅니다.<br><br>\n",
    "Ridge regression은 최소제곱법(OLS)와 유사하나 '각 계수의 제곱을 합한 값'을 식에 포함하여 계수의 크기도 함께 최소화 하도록 만들었다는 차이가 있습니다.<br><br>\n",
    "$ \\min_{w}||X_w - y||_{2}^{2} + \\alpha||w||_{2}^{2} $<br><br>\n",
    "최소값을 구하는 것이 목적이므로 $\\alpha$ 값이 커질 수록 $w$는 0으로 수렴할 것입니다.<br><br>\n",
    "$w$값이 0으로 수렴한다면 아래의 그림과 같이 모델이 단순해지고 과적합을 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img\\\\ridge.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2.1. Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha = .7)\n",
    "reg.fit([[0,0], [0,0],[1,1]], [0, .1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31147541, 0.31147541])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15901639344262297"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2.2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regressor 분석기에는 변형된 분류기인 RidgeClassifier이 있습니다. 이 분류기는 먼저 binary target을 {-1,1} 로 변환한 다음 문제를 회귀 작업으로 처리하여 최적화 합니다.<br>\n",
    "예측된 클래스는 regressor의 예측 부호에 해당합니다. 다중클래스 분류의 경우 문제는 다중 출력 회귀로 처리되고 예측된 클래스는 가장 높은 값을 가진 출력에 해당합니다.<br>\n",
    "\n",
    "보다 전통적인 logistic 또는 hinge loss 대신 분류 모델에 맞추기 위해 Least Squares(최소제곱) loss를 사용하는 것이 의심스러워 보일 수 있습니다.<br>\n",
    "그러나 실제로 이러한 모든 모델은 정확도 또는 정밀도, 재현율 측면에서 유사한 교차 검증 Score로 이어질 수 있는 반면,<br>\n",
    "RidgeCladdifier에서 사용하는 Penalized Least Squares은 고유한 계산 성능 프로필을 가진 수치 솔버의 매우 다른 선택을 허용합니다.<br>\n",
    "\n",
    "RidgeClassifier는 프로젝션 행렬 $(X^{T}X)^{-1}X^{T}$를 한번만 계산 하기 때문에 클래스 수가 많은 LogisticRegression보다 훨씬 빠를 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Ridge coefficients as a function of the regularization**\n",
    "\n",
    "이 예제는 estimator의 계소에서 공선성의 효과를 보여줍니다.\n",
    "\n",
    "Ridge regression은 이 예에서 사용된 estimator입니다. 각 색상은 계수 벡터의 다른 특성을 나타내며 이는 regularization 매개변수의 함수로 표시됩니다.\n",
    "\n",
    "이 예는 또한 조건이 매우 나쁜 행렬에 Ridge regression을 적용하는 것의 유용성을 보여줍니다.<br>\n",
    "이러한 행렬의 경우 목표 변수가 약간 변경되어도 계산된 가중치가 크게 달라질 수 있습니다.<br>\n",
    "이러한 경우 이 변동(Noise)을 줄이기 위해 특정 정규화($\\alpha$)를 설정하는 것이 유용합니다.<br>\n",
    "\n",
    "$\\alpha$ 가 매우 크면 정규화 효과가 제곱 손실 함수를 지배하고 계수는 0이 되는 경향이 있습니다.<br>\n",
    "경로의 끝에서 $\\alpha$는 0을 향하고 솔루션은 일반적인 최소 제곱을 향하는 경향이 있으므로 계수는 큰 진동을 나타냅니다.<br>\n",
    "실제로는 둘 사이의 균형이 유지되는 방식으로 알파를 조정할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# X is the 10x10 Hilbert matrix\n",
    "X = 1.0 / (np.arange(1,11) + np.arange(0,10)[:, np.newaxis])\n",
    "y = np.ones(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compute paths(계산 경로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.logspace(-10, -2, n_alphas)\n",
    "\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha = a, fit_intercept = False)\n",
    "    ridge.fit(X,y)\n",
    "    coefs.append(ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4352\\2693276289.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 10)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(ax.set_xlim()[::-1]) # rever axis\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')\n",
    "plt.title('Ridge coefficients as a function of the regularization')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification of text documents using sparse features**\n",
    "\n",
    "이 예제는 bag-of words 접근 방식을 사용하여 주제별로 문서를 분류하는데 sikit-learn을 사용하는 방법을 보여줍니다.<br>\n",
    "scipy.sparse 해렬을 사용하여 기능을 저장하고 희소 행렬을 효율적으로 처리할 수 있는 다양한 분류기를 보여줍니다.<br>\n",
    "\n",
    "이 예제에서 사용되는 dataset은 20개의 뉴스 그룹 dataset입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Configuration options for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True, we use 'HashingVectorizer', otherwise we use a 'TfidfVectorizer'\n",
    "USE_HASHING = False\n",
    "\n",
    "# Number of features used by 'HashingVectorizer'\n",
    "N_FEATURES = 2**16\n",
    "\n",
    "#Optional feature selection : either False, or an integer : the number of features to select\n",
    "SELECT_CHI2 = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load data from the training set\n",
    "\n",
    "20개의 주제에 대한 약 18000개의 뉴스 그룹 게시물로 구성된 뉴스 그룹 dataset에서 데이터를 load 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(\n",
    "    subset='train', categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "data_test = fetch_20newsgroups(\n",
    "    subset='test', categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in 'target_names' can be different from 'categories\n",
    "target_names = data_train.target_names\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\n",
    "    \"%d documents - %0.3fMB (training set)\" % (len(data_train.data), data_train_size_mb)\n",
    ")\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vectorize the Training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split a training set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = data_train.target, data_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features from the training data using a sparse vectorizer\n",
    "    -> 희소 벡터라이저를 사용하여 훈련 데이터에서 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.357778s at 11.123MB/s\n",
      "n_samples: 2034, n_features: 33809\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "if USE_HASHING:\n",
    "    vectorizer = HashingVectorizer(\n",
    "        stop_words='english', alternate_sign=False, n_features=N_FEATURES\n",
    "    )\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features from the test data using the same vectorizer -> 동일한 벡터라이저를 사용하여 test dat에서 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.191575s at 14.968MB/s\n",
      "n_samples: 1353, n_features: 33809\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapping from integer feature name to original token string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HASHING:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "if SELECT_CHI2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" % SELECT_CHI2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=SELECT_CHI2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names is not None:\n",
    "        # keep selected feature names\n",
    "        feature_names = feature_names[ch2.get_support()]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Benchmark classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 벤치마킨 유틸리티를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.extmath import density\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "def benchmark(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, \"coef_\"):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    print(\"classification report:\")\n",
    "    print(metrics.classification_report(y_test, pred, target_names=target_names))\n",
    "\n",
    "    print(\"confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 15개의 서로 다른 분류 모델로 데이터 세트를 훈련 및 테스트하고 각 모델에 대한 성능 결과를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(solver='sag', tol=0.01)\n",
      "train time: 0.102s\n",
      "test time:  0.001s\n",
      "accuracy:   0.897\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: osrhe atheist wingate god okcforum caltech islamic atheism keith...\n",
      "comp.graphics: animation video looking card hi 3d thanks file image graphics\n",
      "sci.space: dc flight shuttle launch pat moon sci orbit nasa space\n",
      "talk.religion.misc: jesus mitre hudson morality biblical 2000 beast mr fbi ch...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.87      0.83      0.85       319\n",
      "     comp.graphics       0.90      0.98      0.94       389\n",
      "         sci.space       0.96      0.94      0.95       394\n",
      "talk.religion.misc       0.83      0.78      0.80       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.88      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[265   9   7  38]\n",
      " [  1 382   3   3]\n",
      " [  0  22 372   0]\n",
      " [ 40  10   6 195]]\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(max_iter=50)\n",
      "train time: 0.014s\n",
      "test time:  0.001s\n",
      "accuracy:   0.888\n",
      "dimensionality: 33809\n",
      "density: 0.255302\n",
      "top 10 keywords per class:\n",
      "alt.atheism: wingate osrhe freedom lippard alt thing cobb atheists atheism keith\n",
      "comp.graphics: siggraph code fractal comp mpeg library pc animation sphere gr...\n",
      "sci.space: bruce wpi solar sci funding moon orbit planets dc space\n",
      "talk.religion.misc: god morality hudson beast sword fbi 2000 order mr christian\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.86      0.80      0.83       319\n",
      "     comp.graphics       0.90      0.97      0.94       389\n",
      "         sci.space       0.95      0.93      0.94       394\n",
      "talk.religion.misc       0.79      0.80      0.79       251\n",
      "\n",
      "          accuracy                           0.89      1353\n",
      "         macro avg       0.88      0.88      0.88      1353\n",
      "      weighted avg       0.89      0.89      0.89      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[256   7   8  48]\n",
      " [  0 379   4   6]\n",
      " [  7  21 366   0]\n",
      " [ 33  12   6 200]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(max_iter=50)\n",
      "train time: 0.015s\n",
      "test time:  0.001s\n",
      "accuracy:   0.905\n",
      "dimensionality: 33809\n",
      "density: 0.701677\n",
      "top 10 keywords per class:\n",
      "alt.atheism: osrhe wingate islam okcforum caltech atheist islamic keith athei...\n",
      "comp.graphics: thanks video tiff hi files animation 3d file image graphics\n",
      "sci.space: henry shuttle dc pat launch sci nasa moon orbit space\n",
      "talk.religion.misc: christians biblical 666 hudson fbi beast morality mr 2000...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.86      0.84      0.85       319\n",
      "     comp.graphics       0.94      0.97      0.95       389\n",
      "         sci.space       0.95      0.96      0.96       394\n",
      "talk.religion.misc       0.83      0.80      0.81       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.89      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[269   5   9  36]\n",
      " [  2 377   5   5]\n",
      " [  2  14 378   0]\n",
      " [ 39   7   5 200]]\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(n_neighbors=10)\n",
      "train time: 0.001s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:730: UserWarning: \"sag\" solver requires many iterations to fit an intercept with sparse inputs. Either set the solver to \"auto\" or \"sparse_cg\", or set a low \"tol\" and a high \"max_iter\" (especially if inputs are not standardized).\n",
      "  '\"sag\" solver requires many iterations to fit '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.140s\n",
      "accuracy:   0.858\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.78      0.90      0.84       319\n",
      "     comp.graphics       0.89      0.89      0.89       389\n",
      "         sci.space       0.90      0.91      0.90       394\n",
      "talk.religion.misc       0.86      0.67      0.75       251\n",
      "\n",
      "          accuracy                           0.86      1353\n",
      "         macro avg       0.86      0.84      0.85      1353\n",
      "      weighted avg       0.86      0.86      0.86      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[287   3  11  18]\n",
      " [ 14 348  19   8]\n",
      " [  7  26 359   2]\n",
      " [ 59  13  12 167]]\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier()\n",
      "train time: 0.854s\n",
      "test time:  0.054s\n",
      "accuracy:   0.840\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.86      0.74      0.80       319\n",
      "     comp.graphics       0.80      0.97      0.87       389\n",
      "         sci.space       0.93      0.88      0.90       394\n",
      "talk.religion.misc       0.77      0.70      0.73       251\n",
      "\n",
      "          accuracy                           0.84      1353\n",
      "         macro avg       0.84      0.82      0.83      1353\n",
      "      weighted avg       0.84      0.84      0.84      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[236  26   8  49]\n",
      " [  1 378   7   3]\n",
      " [  2  43 348   1]\n",
      " [ 35  28  13 175]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, tol=0.001)\n",
      "train time: 0.043s\n",
      "test time:  0.001s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: rushdie osrhe atheist wingate okcforum caltech islamic atheism k...\n",
      "comp.graphics: code 42 video hi animation thanks 3d file image graphics\n",
      "sci.space: planets dc pat shuttle launch sci moon nasa orbit space\n",
      "talk.religion.misc: abortion hudson 666 biblical 2000 morality mr beast fbi c...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.87      0.83      0.85       319\n",
      "     comp.graphics       0.91      0.98      0.95       389\n",
      "         sci.space       0.96      0.95      0.95       394\n",
      "talk.religion.misc       0.83      0.79      0.81       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.89      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[266   7   8  38]\n",
      " [  2 381   3   3]\n",
      " [  1  20 373   0]\n",
      " [ 38   9   6 198]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50)\n",
      "train time: 0.019s\n",
      "test time:  0.001s\n",
      "accuracy:   0.903\n",
      "dimensionality: 33809\n",
      "density: 0.588993\n",
      "top 10 keywords per class:\n",
      "alt.atheism: osrhe bible wingate okcforum cobb caltech islamic keith atheism ...\n",
      "comp.graphics: 3do tiff hi video 42 3d animation file image graphics\n",
      "sci.space: shuttle pat planets launch sci dc moon nasa orbit space\n",
      "talk.religion.misc: mitre abortion 666 biblical fbi morality mr 2000 beast ch...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.87      0.84      0.86       319\n",
      "     comp.graphics       0.93      0.97      0.95       389\n",
      "         sci.space       0.95      0.95      0.95       394\n",
      "talk.religion.misc       0.83      0.81      0.82       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.89      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[268   5  10  36]\n",
      " [  2 377   5   5]\n",
      " [  1  18 374   1]\n",
      " [ 36   7   5 203]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(dual=False, penalty='l1', tol=0.001)\n",
      "train time: 0.143s\n",
      "test time:  0.002s\n",
      "accuracy:   0.873\n",
      "dimensionality: 33809\n",
      "density: 0.005553\n",
      "top 10 keywords per class:\n",
      "alt.atheism: benedikt rice rushdie wingate islamic bmd atheism wwc keith athe...\n",
      "comp.graphics: sphere virtual 42 files windows hi image 3d 3do graphics\n",
      "sci.space: sunrise pat henry rockets dc launch flight moon orbit space\n",
      "talk.religion.misc: hudson thyagi biblical 2000 abortion kendig hare mitre ch...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.75      0.80       319\n",
      "     comp.graphics       0.89      0.97      0.93       389\n",
      "         sci.space       0.94      0.94      0.94       394\n",
      "talk.religion.misc       0.76      0.78      0.77       251\n",
      "\n",
      "          accuracy                           0.87      1353\n",
      "         macro avg       0.86      0.86      0.86      1353\n",
      "      weighted avg       0.87      0.87      0.87      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[238  14  11  56]\n",
      " [  0 378   7   4]\n",
      " [  2  22 369   1]\n",
      " [ 39  12   4 196]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='l1')\n",
      "train time: 0.071s\n",
      "test time:  0.001s\n",
      "accuracy:   0.886\n",
      "dimensionality: 33809\n",
      "density: 0.023640\n",
      "top 10 keywords per class:\n",
      "alt.atheism: lippard rice perry charley wingate rushdie islamic keith atheist...\n",
      "comp.graphics: 3d polygon sphere files file comp 3do animation image graphics\n",
      "sci.space: sci solar rockets nasa dc launch flight moon orbit space\n",
      "talk.religion.misc: hudson biblical 666 mitre homosexuality mr abortion beast...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.86      0.78      0.82       319\n",
      "     comp.graphics       0.92      0.97      0.95       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.77      0.78      0.77       251\n",
      "\n",
      "          accuracy                           0.89      1353\n",
      "         macro avg       0.87      0.87      0.87      1353\n",
      "      weighted avg       0.89      0.89      0.88      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[248   8  11  52]\n",
      " [  1 377   6   5]\n",
      " [  2  12 378   2]\n",
      " [ 36  11   8 196]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(max_iter=50, penalty='elasticnet')\n",
      "train time: 0.095s\n",
      "test time:  0.001s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 0.186304\n",
      "top 10 keywords per class:\n",
      "alt.atheism: caltech charley okcforum rushdie cobb wingate islamic keith athe...\n",
      "comp.graphics: computer hi points 3do 42 3d file animation image graphics\n",
      "sci.space: shuttle planets flight sci launch dc nasa moon orbit space\n",
      "talk.religion.misc: order abortion biblical morality 666 mr 2000 fbi beast ch...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.87      0.83      0.85       319\n",
      "     comp.graphics       0.94      0.97      0.95       389\n",
      "         sci.space       0.94      0.96      0.95       394\n",
      "talk.religion.misc       0.81      0.79      0.80       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.89      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[264   5  11  39]\n",
      " [  1 379   4   5]\n",
      " [  2  14 377   1]\n",
      " [ 38   7   8 198]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid()\n",
      "train time: 0.003s\n",
      "test time:  0.004s\n",
      "accuracy:   0.855\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.88      0.69      0.77       319\n",
      "     comp.graphics       0.84      0.97      0.90       389\n",
      "         sci.space       0.96      0.92      0.94       394\n",
      "talk.religion.misc       0.72      0.79      0.75       251\n",
      "\n",
      "          accuracy                           0.86      1353\n",
      "         macro avg       0.85      0.84      0.84      1353\n",
      "      weighted avg       0.86      0.86      0.85      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[219  25   5  70]\n",
      " [  1 379   5   4]\n",
      " [  1  30 361   2]\n",
      " [ 29  19   5 198]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01)\n",
      "train time: 0.003s\n",
      "test time:  0.001s\n",
      "accuracy:   0.899\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: say livesey article don people atheists com caltech god keith\n",
      "comp.graphics: file image com files nntp host posting thanks university graphics\n",
      "sci.space: pat moon digex henry article access gov com nasa space\n",
      "talk.religion.misc: apple don kent article people sandvik jesus christian god...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.87      0.86       319\n",
      "     comp.graphics       0.95      0.95      0.95       389\n",
      "         sci.space       0.92      0.95      0.94       394\n",
      "talk.religion.misc       0.86      0.77      0.81       251\n",
      "\n",
      "          accuracy                           0.90      1353\n",
      "         macro avg       0.89      0.89      0.89      1353\n",
      "      weighted avg       0.90      0.90      0.90      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[279   2   8  30]\n",
      " [  2 369  16   2]\n",
      " [  3  15 376   0]\n",
      " [ 45   4   9 193]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01)\n",
      "train time: 0.006s\n",
      "test time:  0.003s\n",
      "accuracy:   0.884\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: god say think people don com nntp host posting article\n",
      "comp.graphics: like com article know thanks graphics university nntp host pos...\n",
      "sci.space: nasa like university just com nntp host posting space article\n",
      "talk.religion.misc: think know christian posting god people just don article com\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.83      0.88      0.86       319\n",
      "     comp.graphics       0.88      0.96      0.92       389\n",
      "         sci.space       0.94      0.91      0.92       394\n",
      "talk.religion.misc       0.87      0.73      0.79       251\n",
      "\n",
      "          accuracy                           0.88      1353\n",
      "         macro avg       0.88      0.87      0.87      1353\n",
      "      weighted avg       0.88      0.88      0.88      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[282   9   3  25]\n",
      " [  1 373  13   2]\n",
      " [  5  31 358   0]\n",
      " [ 50  10   8 183]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "ComplementNB(alpha=0.1)\n",
      "train time: 0.003s\n",
      "test time:  0.001s\n",
      "accuracy:   0.911\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "top 10 keywords per class:\n",
      "alt.atheism: bake beauchaine mangoe buphy rushdie jaeger schneider mozumder i...\n",
      "comp.graphics: swix swivel swiv3d switzerland pov vga cview vesa tiff polygon\n",
      "sci.space: kinetic engines gehrels zoology prb acad3 nsmca dseg spacecraft mc...\n",
      "talk.religion.misc: muscles dclxvi 93apr9160836 ssan dba mustard db muttiah s...\n",
      "\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.85      0.89      0.87       319\n",
      "     comp.graphics       0.95      0.97      0.96       389\n",
      "         sci.space       0.94      0.97      0.95       394\n",
      "talk.religion.misc       0.88      0.75      0.81       251\n",
      "\n",
      "          accuracy                           0.91      1353\n",
      "         macro avg       0.90      0.90      0.90      1353\n",
      "      weighted avg       0.91      0.91      0.91      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[284   2   8  25]\n",
      " [  2 379   7   1]\n",
      " [  0  13 381   0]\n",
      " [ 49   5   9 188]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False, penalty='l1',\n",
      "                                                     tol=0.001))),\n",
      "                ('classification', LinearSVC())])\n",
      "train time: 0.155s\n",
      "test time:  0.002s\n",
      "accuracy:   0.880\n",
      "classification report:\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       alt.atheism       0.84      0.80      0.82       319\n",
      "     comp.graphics       0.91      0.96      0.93       389\n",
      "         sci.space       0.93      0.95      0.94       394\n",
      "talk.religion.misc       0.81      0.76      0.78       251\n",
      "\n",
      "          accuracy                           0.88      1353\n",
      "         macro avg       0.87      0.87      0.87      1353\n",
      "      weighted avg       0.88      0.88      0.88      1353\n",
      "\n",
      "confusion matrix:\n",
      "[[254  11  13  41]\n",
      " [  2 374   9   4]\n",
      " [  2  18 373   1]\n",
      " [ 44   9   8 190]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\user\\anaconda3\\envs\\deep\\lib\\site-packages\\sklearn\\utils\\deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "    (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
    "    (Perceptron(max_iter=50), \"Perceptron\"),\n",
    "    (PassiveAggressiveClassifier(max_iter=50), \"Passive-Aggressive\"),\n",
    "    (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "    (RandomForestClassifier(), \"Random forest\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False, tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print(\"=\" * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(\n",
    "    benchmark(SGDClassifier(alpha=0.0001, max_iter=50, penalty=\"elasticnet\"))\n",
    ")\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print(\"=\" * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print(\"=\" * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=0.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=0.01)))\n",
    "results.append(benchmark(ComplementNB(alpha=0.1)))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(\n",
    "    benchmark(\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\n",
    "                    \"feature_selection\",\n",
    "                    SelectFromModel(LinearSVC(penalty=\"l1\", dual=False, tol=1e-3)),\n",
    "                ),\n",
    "                (\"classification\", LinearSVC(penalty=\"l2\")),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "막대 플롯은 각 분류기의 정확도, 훈련 시간(정규화) 및 테스트 시간(정규화)을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, 0.2, label=\"score\", color=\"navy\")\n",
    "plt.barh(indices + 0.3, training_time, 0.2, label=\"training time\", color=\"c\")\n",
    "plt.barh(indices + 0.6, test_time, 0.2, label=\"test time\", color=\"darkorange\")\n",
    "plt.yticks(())\n",
    "plt.legend(loc=\"best\")\n",
    "plt.subplots_adjust(left=0.25)\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.subplots_adjust(bottom=0.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-0.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "21278c9276100b1652f3f92759879876200e410586490b47d4aac09db8da8794"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
